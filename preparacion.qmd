---
title: "Preparación de los Datos"
---

```{r, echo=FALSE}
# Configuración general del documento
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
# Cargar librerías
suppressWarnings(suppressMessages(source("librerias.R")))
```

```{r}
# Forzar regeneración si es necesario
regenerar_csv <- FALSE  # Cambiar a TRUE si quieres que se ejecute siempre

if (!file.exists("StudentPerformanceFactors_Cleaned.csv") || regenerar_csv) {
  source("preparacion_inicial.R")
}

# Cargar el archivo CSV preparado
student_data <- read.csv("StudentPerformanceFactors_Cleaned.csv")
```

```{r}
# Convertir variables categóricas a factores con orden
student_data$Nivel_Motivacion <- factor(student_data$Nivel_Motivacion, 
                                        levels = c("Baja", "Media", "Alta"), 
                                        ordered = TRUE)

student_data$Involucramiento_Parental <- factor(student_data$Involucramiento_Parental, 
                                                levels = c("Bajo", "Medio", "Alto"), 
                                                ordered = TRUE)

student_data$Calidad_Profesor <- factor(student_data$Calidad_Profesor,
                                        levels = c("Baja", "Media", "Alta"), 
                                        ordered = TRUE)

student_data$Tipo_Escuela <- factor(student_data$Tipo_Escuela,
                                    levels = c("Publica", "Privada")) 

student_data$Sexo <- factor(student_data$Sexo, 
                            levels = c("Femenino", "Masculino")) 

student_data$Ingresos_Familiares <- factor(student_data$Ingresos_Familiares, 
                                           levels = c("Bajo", "Medio", "Alto"), 
                                           ordered = TRUE)

student_data$Influencia_Companeros <- factor(student_data$Influencia_Companeros, 
                                             levels = c("Negativa", "Neutral", "Positiva"), 
                                             ordered = TRUE)

student_data$Actividades_Extracurriculares <- factor(student_data$Actividades_Extracurriculares, 
                                                     levels = c("No", "Si"), 
                                           ordered = TRUE)

student_data$Acceso_Internet <- factor(student_data$Acceso_Internet, 
                                       levels = c("No", "Si"), 
                                           ordered = TRUE)

student_data$Discapacidades_Aprendizaje <- factor(student_data$Discapacidades_Aprendizaje, 
                                                  levels = c("No", "Si"), 
                                           ordered = TRUE)

student_data$Nivel_Educativo_Padres <- factor(student_data$Nivel_Educativo_Padres, 
                                              levels = c("Secundaria", "Universitaria", "Postgrado"), 
                                              ordered = TRUE)

student_data$Acceso_Recursos <- factor(student_data$Acceso_Recursos,
                                       levels = c("Bajo", "Medio", "Alto"), 
                                       ordered = TRUE)

student_data$Distancia_Hogar <- factor(student_data$Distancia_Hogar,
                                       levels = c("Cerca", "Moderado", "Lejos"), 
                                       ordered = TRUE)
```

Es necesario realizar una preparación del conjunto de datos que considera correción de errores estructurales, filtrado de registros duplicados, gestión de valores atípicos, faltantes, validación y control de la calidad de los datos. Además, de la matriz de correlacion y las transformaciones de variables necesarias para los analisis posteriores.

## Evaluación de la Calidad de los Datos

### Identificación de Valores Duplicados

Eliminar registros duplicados garantiza que cada observación sea única y evita sesgos en el análisis. Los duplicados pueden distorsionar las estadísticas y afectar el desempeño del modelo al dar un peso desproporcionado a datos repetidos.

```{r}
# Identificar registros duplicados
datos_duplicados <- student_data %>% filter(duplicated(.))
cat("Registros duplicados encontrados: ", nrow(datos_duplicados))
```

No se identifican registros duplicados, lo que confirma la integridad inicial del conjunto de datos.

### Manejo de Valores Faltantes

Se evalúa la cantidad y distribución de los valores faltantes en el conjunto de datos para identificar posibles problemas que puedan afectar los análisis.

```{r}
# Calcular valores faltantes y porcentaje
valores_faltantes <- student_data %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valores_Faltantes") %>%
  mutate(`Porcentaje (%)` = round((Valores_Faltantes / nrow(student_data)) * 100, 2))

# Crear tabla con flextable
tabla_valores_faltantes <- valores_faltantes %>%
  flextable() %>%
  set_header_labels(
    Variable = "Variable",
    Valores_Faltantes = "Valores Faltantes",
    `Porcentaje (%)` = "Porcentaje (%)"
  ) %>%
  autofit()

# Mostrar la tabla (en un documento R Markdown o Quarto)
tabla_valores_faltantes
```

Los resultados muestran valores faltantes mínimos, que no deberían afectar significativamente el análisis posterior:

-   **Calidad del Profesor**: 78 valores faltantes (1.18%).\
-   **Nivel educativo de los padres**: 90 valores faltantes (1.36%).\
-   **Distancia del Hogar**: 67 valores faltantes (1.01%)

En lugar de imputar valores como la media, que podría introducir sesgo, se eliminan los registros faltantes de las variables clave para garantizar la calidad de los datos.

```{r}
# Eliminar registros con NA en todas las variables relevantes
student_data <- student_data %>% drop_na()

# Verificar la cantidad de datos después de eliminar los NA
summary(student_data)
```

### Manejo de Valores Atípicos

Los valores atípicos pueden distorsionar estadísticas descriptivas, como la media, y afectar modelos predictivos al dar peso desproporcionado a registros extremos. Para identificarlos, se utilizó el **rango intercuartílico (IQR)** y se analizó su impacto en la distribución.

#### Detección de Valores Atípicos

Primero se identificaron los valores atípicos mediante el cálculo del IQR. A continuación, se presenta la cantidad y el porcentaje de valores atípicos por variable:

```{r}
# Función para detectar valores atípicos con IQR
detectar_atipicos <- function(variable) {
  Q1 <- quantile(variable, 0.25, na.rm = TRUE)  # Primer cuartil
  Q3 <- quantile(variable, 0.75, na.rm = TRUE)  # Tercer cuartil
  IQR <- Q3 - Q1  # Rango intercuartil
  limite_inferior <- Q1 - 1.5 * IQR
  limite_superior <- Q3 + 1.5 * IQR
  sum(variable < limite_inferior | variable > limite_superior, na.rm = TRUE)
}

# Seleccionar variables numéricas
variables_numericas <- student_data %>%
  select_if(is.numeric)

# Nombres en español para las variables
nombres_espanol <- c(
  "Horas de Estudio", 
  "Asistencia", 
  "Horas de Sueño", 
  "Puntuaciones Previas", 
  "Sesiones de Tutoría", 
  "Actividad Física", 
  "Puntuación de Examen"
)

# Calcular atípicos y porcentajes
atipicos_totales <- data.frame(
  Variable = nombres_espanol,  # Solo nombres en español
  Atipicos = sapply(variables_numericas, detectar_atipicos)
)

# Agregar porcentaje
total_observaciones <- nrow(student_data)
atipicos_totales <- atipicos_totales %>%
  mutate(Porcentaje = round((Atipicos / total_observaciones) * 100, 2))

# Crear la tabla con flextable
tabla_atipicos <- atipicos_totales %>%
  flextable() %>%
  set_header_labels(Variable = "Variable", Atipicos = "Atípicos", Porcentaje = "(%)") %>%
  autofit()

# Mostrar la tabla (en un documento R Markdown o Quarto)
tabla_atipicos
```

Al recalcular los valores atípicos tras la eliminación de registros con valores faltantes, se observó una reducción en el número de estos, aunque se identificaron en las mismas variables que en el análisis exploratorio inicial. Este ajuste refleja el impacto de trabajar con un dataset depurado, lo que modifica ligeramente los cálculos estadísticos, como el rango intercuartílico (IQR).

Específicamente, los valores atípicos disminuyeron de la siguiente manera:

-   En **Horas de Estudio**, se redujeron de 43 a 40 observaciones, representando el 0.63% del total.
-   En **Sesiones de Tutoría**, disminuyeron de 430 a 423 observaciones, lo que equivale al 6.63% del total.
-   En **Puntuación de Examen**, pasaron de 104 a 103 observaciones, representando el 1.61% del total.

```{r, fig.width=14, fig.height=5}
# Crear datos filtrados
variables <- student_data %>% 
  select(Horas_Estudio, Sesiones_Tutoria, Puntuacion_Examen)

nombres <- c("Horas de Estudio", "Sesiones de Tutoría", "Puntuación de Examen")

# Gráfico 1: Horas de Estudio
grafico1 <- ggplot(student_data, aes(y = Horas_Estudio)) +
  geom_boxplot(fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Horas de Estudio", y = "Horas", x = "") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Gráfico 2: Sesiones de Tutoría
grafico2 <- ggplot(student_data, aes(y = Sesiones_Tutoria)) +
  geom_boxplot(fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Sesiones de Tutoría", y = "Sesiones", x = "") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )
# Mostrar los gráficos
grid.arrange(grafico1, grafico2, ncol = 2)
```

```{r, fig.width=14, fig.height=5}
# Gráfico 3: Puntuación de Examen
grafico3 <- ggplot(student_data, aes(y = Puntuacion_Examen)) +
  geom_boxplot(fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Puntuación de Examen", y = "Puntuación", x = "") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar los gráficos organizados
grid.arrange(grafico3, ncol = 2)
```

En las variables **Horas de Estudio** y **Puntuación de Examen** no se intervendra en los valores atípicos, ya que aparentemente representan comportamientos extremos válidos. Se usara la mediana o el valor transformado si afecta mucho la media.

En relación a las **Sesiones de Tutoría**, dado el 6.63% de valores atípicos y estan en la parte alta, donde se mejora la mediana, se intentara explicar su naturaleza y hacer transformaciones de esta variable para intentar reducir el efecto de los extremos.

#### Interpretación de los Valores Atípicos

Al analizar las Sesiones de Tutoría, observamos que los valores atípicos en la cola derecha pueden reflejar un fenómeno importante:

-   Los estudiantes que asisten a más sesiones de tutoría pueden ser aquellos con necesidades académicas especiales, estudiantes en recuperación o aquellos que buscan maximizar su rendimiento.

-   Como se observa en la relación entre Sesiones de Tutoría y Puntuación de Examen, estos valores atípicos están correlacionados con mejores puntuaciones, sugiriendo que la tutoría podría estar cumpliendo su objetivo educativo.

-   En un contexto educativo real, este hallazgo sería relevante para diseñar estrategias de intervención. Los valores extremos no deben descartarse sin antes analizar si representan estudiantes de alto rendimiento o situaciones especiales, como programas de apoyo escolar intensivo.

#### Conclusión

Los valores atípicos identificados en las variables Horas de Estudio, Sesiones de Tutoría y Puntuación de Examen reflejan comportamientos extremos que, en algunos casos, tienen sentido práctico dentro del contexto educativo. Por ejemplo, los valores altos en Sesiones de Tutoría están asociados con mejores puntuaciones en los exámenes, lo que podría deberse a intervenciones educativas específicas o un mayor esfuerzo académico.

No se aplicará ninguna transformación en esta etapa. Los valores atípicos serán evaluados nuevamente en el apartado Transformación de Variables, donde se analizará si es necesario aplicar ajustes, para corregir asimetrías o reducir el impacto de valores extremos en los modelos.

En etapas posteriores del análisis, se determinará si las variables originales o transformadas mejoran el desempeño de los modelos predictivos.

## Matriz de Correlación

La matriz de correlación se utiliza para analizar la relación lineal entre las variables numéricas del conjunto de datos. Este paso es importante porque permite identificar qué variables tienen una mayor asociación con la Puntuación de Examen, que es la variable dependiente, y también ayuda a detectar posibles problemas de colinealidad entre las variables explicativas.

```{r}
# Matriz de Correlación

# Seleccionar solo las variables numéricas
variables_numericas <- student_data %>% 
  select(Horas_Estudio, Asistencia, Horas_Sueno,     Puntuaciones_Previas, Sesiones_Tutoria, Actividad_Fisica, Puntuacion_Examen)

# Calcular la matriz de correlación
matriz_cor <- cor(variables_numericas, use = "pairwise.complete.obs")

# Visualización de la matriz de correlación
corrplot(matriz_cor, 
         method = "color",       
         type = "upper",         
         tl.col = "black",       
         tl.srt = 45,     
         addCoef.col = "black", 
         number.cex = 0.7, 
         col = colorRampPalette(c("red", "white","blue"))(200)) 
```

La matriz de correlación presentada muestra las relaciones lineales entre las variables numéricas del conjunto de datos. Su interpretación se detalla a continuación.

-   Relaciones fuertes:
    -   La variable **Asistencia** presenta la correlación más alta con la **Puntuación de Examen** (0.58). Esto indica que los estudiantes con mayor asistencia tienden a obtener mejores resultados académicos.

    -   **Horas de Estudio** también muestra una correlación moderada (0.45), confirmando su impacto positivo en el rendimiento académico.
-   Relaciones débiles:
    -   Las variables **Sesiones de Tutoría** (0.16) y **Puntuaciones Previas** (0.18) presentan una correlación leve con la **Puntuación de Examen**, lo que sugiere un impacto menor.
-   Sin correlación significativa:
    -   Variables como **Horas de Sueño** y **Actividad Física** tienen valores de correlación cercanos a cero con **Puntuación de Examen**, sugiriendo que no tienen una relación lineal relevante.

Si bien la matriz de correlación permite identificar relaciones entre variables, también sugiere posibles problemas de **colinealidad**. La colinealidad ocurre cuando dos o más variables explicativas están altamente correlacionadas, lo que puede afectar la interpretación de los coeficientes en un modelo predictivo. Para confirmar la presencia o ausencia de colinealidad, se procede a evaluar el **Factor de Inflación de Varianza (VIF)**.

### Evaluación de Colinealidad

Aunque la matriz de correlación permite identificar relaciones entre variables, también es importante analizar la colinealidad entre las variables explicativas. La colinealidad ocurre cuando dos o más variables independientes están altamente correlacionadas, lo que puede generar:

-   Inestabilidad en los coeficientes del modelo.

-   Problemas de interpretación de los resultados.

Para evaluar la colinealidad, se utiliza el Factor de Inflación de Varianza (VIF):

```{r}
# Calcular el VIF para identificar colinealidad
modelo_vif <- lm(Puntuacion_Examen ~ Horas_Estudio + Asistencia + Horas_Sueno + Puntuaciones_Previas + 
                 Sesiones_Tutoria + Actividad_Fisica, data = student_data)

vif_result <- vif(modelo_vif)

# Mostrar resultados del VIF
vif_result <- data.frame(Variable = names(vif_result), VIF = vif_result)
kable(vif_result, caption = "Factor de Inflación de Varianza (VIF)", digits = 2)

```

#### Interpretación de los Resultados del VIF

**Regla general**:

\- Un VIF menor a 5 indica que no existe colinealidad significativa.\
- Un VIF entre 5 y 10 sugiere colinealidad moderada.\
- Un VIF mayor a 10 indica colinealidad alta y requiere intervención.

**Resultados observados**:

Todos los valores de VIF son menores a 5, lo que sugiere que **no existe colinealidad significativa** entre las variables seleccionadas. Por lo tanto, estas variables pueden ser incluidas en el modelo sin necesidad de ajustes adicionales.

#### Conclusión

La matriz de correlación muestra las relaciones lineales entre las variables numéricas y la Puntuación de Examen. Se observan correlaciones importantes, como Asistencia (0.58) y Horas de Estudio (0.45), mientras que otras variables presentan una relación débil o nula.

La evaluación del VIF confirma que no existe colinealidad significativa entre las variables explicativas, lo que sugiere que no será necesario realizar ajustes adicionales en este aspecto por ahora. Sin embargo, se continuará evaluando las variables numéricas en etapas posteriores del análisis, especialmente al validar los resultados del modelo.

## Transformación de Variables

La transformación de variables se realiza para corregir problemas de distribución, reducir el efecto de valores extremos y mejorar la relación lineal entre las variables en un análisis predictivo. Este paso es especialmente útil para garantizar que las variables numéricas estén adecuadamente preparadas para modelos sensibles a la escala, como la regresión lineal.

En este apartado, se aplicaron diferentes técnicas de transformación a variables seleccionadas para evaluar su impacto en la distribución y su relación con la variable dependiente, Puntuación de Examen. Además, se consideró la normalización de variables numéricas como un paso clave para asegurar la coherencia en el modelo.

### Transformación de Sesiones de Tutoría

La variable **Sesiones de Tutoría** presenta una distribución asimétrica hacia la derecha (asimetría positiva), lo que sugiere la necesidad de una transformación logarítmica para reducir el impacto de los valores atípicos.

```{r}
# Transformar Sesiones de Tutoría
student_data$Sesiones_Tutoria_log <- log1p(student_data$Sesiones_Tutoria)

# Validación rápida
summary(student_data$Sesiones_Tutoria_log)
```

#### Gráficos Comparativos

```{r, fig.width=14, fig.height=5}
# Histograma antes de la transformación
hist_original <- ggplot(student_data, aes(x = Sesiones_Tutoria)) +
  geom_histogram(bins = 10, fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Histograma Original de Sesiones de Tutoría", 
       x = "Sesiones de Tutoría", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Histograma después de la transformación
hist_transformado <- ggplot(student_data, aes(x = Sesiones_Tutoria_log)) +
  geom_histogram(bins = 10, fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Histograma Transformado de Sesiones de Tutoría", 
       x = "log(1 + Sesiones de Tutoría)", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar los gráficos
grid.arrange(hist_original, hist_transformado, ncol = 2)
```

```{r, fig.width=14, fig.height=5, echo=FALSE}
# Boxplot antes de la transformación
box_original <- ggplot(student_data, aes(y = Sesiones_Tutoria)) +
  geom_boxplot(fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Boxplot Original de Sesiones de Tutoría", 
       y = "Sesiones de Tutoría", x = "") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Boxplot después de la transformación
box_transformado <- ggplot(student_data, aes(y = Sesiones_Tutoria_log)) +
  geom_boxplot(fill = "#5BC0EB", color = "#0A4275", alpha = 0.8) +
  theme_minimal(base_size = 12) +
  labs(title = "Boxplot Transformado de Sesiones de Tutoría", 
       y = "log(1 + Sesiones de Tutoría)") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar boxplots en una fila
grid.arrange(box_original, box_transformado, ncol = 2)
```

#### Análisis de la Transformación

La transformación logarítmica aplicada a la variable Sesiones de Tutoría logra reducir la asimetría positiva de su distribución, compactando la cola derecha y disminuyendo el impacto de los valores extremos. Sin embargo, también introduce una concentración de valores bajos y nuevos valores atípicos en esta zona, lo que podría influir en la interpretación del modelo.

Al considerar el contexto educativo, los valores atípicos en la parte alta representan un fenómeno relevante (mayor número de sesiones de tutoría asociado a un mejor rendimiento), por lo que la decisión de transformar o no esta variable dependerá del impacto en el modelo final.

### Transformación de Asistencia

La variable **Asistencia** muestra una distribución no normal. Para evaluar su posible mejora, se aplicaron tres transformaciones: logarítmica, raíz cuadrada y Box-Cox.

```{r, echo=FALSE}
# Transformaciones
student_data$Asistencia_log <- log1p(student_data$Asistencia)     # Logarítmica
student_data$Asistencia_sqrt <- sqrt(student_data$Asistencia)     # Raíz Cuadrada

# Box-Cox requiere que los valores sean positivos y sin ceros
boxcox_model <- BoxCoxTrans(student_data$Asistencia)
student_data$Asistencia_boxcox <- predict(boxcox_model, student_data$Asistencia)
```

#### Gráficos Comparativos

```{r, fig.width=14, fig.height=5}
# Histograma Original
hist_original <- ggplot(student_data, aes(x = Asistencia)) +
  geom_histogram(bins = 10, fill = "#0A4275", color = "black", alpha = 0.8) +
  theme_minimal() +
  labs(title = "Asistencia Original", x = "Asistencia", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Histograma Logarítmico
hist_log <- ggplot(student_data, aes(x = Asistencia_log)) +
  geom_histogram(bins = 10, fill = "#5BC0EB", color = "black", alpha = 0.8) +
  theme_minimal() +
  labs(title = "Asistencia Log Transformada", x = "log(1 + Asistencia)", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar gráficos
grid.arrange(hist_original, hist_log, ncol = 2)
```

```{r, fig.width=14, fig.height=5, echo=FALSE}
# Histograma Raíz Cuadrada
grafico_sqrt <- ggplot(student_data, aes(x = Asistencia_sqrt)) +
  geom_histogram(bins = 10, fill = "#5BC0EB", color = "black", alpha = 0.8) +
  theme_minimal() +
  labs(title = "Asistencia Raíz Cuadrada", x = "sqrt(Asistencia)", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Histograma Box-Cox
grafico_boxcox <- ggplot(student_data, aes(x = Asistencia_boxcox)) +
  geom_histogram(bins = 10, fill = "#5BC0EB", color = "black", alpha = 0.8) +
  theme_minimal() +
  labs(title = "Asistencia Box-Cox Transformada", x = "Box-Cox(Asistencia)", y = "Frecuencia") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar gráficos en una fila
grid.arrange(grafico_sqrt, grafico_boxcox, ncol = 2)
```

En los histogramas se observa que la Asistencia Original tiene una distribución uniforme entre 60% y 100% y se compara con las transformaciones:

-   Transformación Logarítmica: compacta los valores bajos y suaviza ligeramente la cola alta. Sin embargo, no corrige por completo la distribución.

-   Transformación Raíz Cuadrada: es la más equilibrada, ya que reduce de manera uniforme los valores extremos bajos y altos sin distorsionar la estructura central de los datos.

-   Transformación Box-Cox: ajusta principalmente los valores altos.

```{r, fig.width=14, fig.height=5}
# Gráfico Original
grafico_corr_original <- ggplot(student_data, aes(x = Asistencia, y = Puntuacion_Examen)) +
  geom_point(color = "#0A4275", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Asistencia Original vs Puntuación", 
       x = "Asistencia", y = "Puntuación de Examen") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Gráfico Logarítmico
grafico_corr_log <- ggplot(student_data, aes(x = Asistencia_log, y = Puntuacion_Examen)) +
  geom_point(color = "#5BC0EB", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Asistencia Log Transformada vs Puntuación", 
       x = "log(1 + Asistencia)", y = "Puntuación de Examen") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar en una fila
grid.arrange(grafico_corr_original, grafico_corr_log, ncol = 2)
```

```{r, fig.width=14, fig.height=5}
# Gráfico Raíz Cuadrada
grafico_corr_sqrt <- ggplot(student_data, aes(x = Asistencia_sqrt, y = Puntuacion_Examen)) +
  geom_point(color = "#5BC0EB", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Asistencia Raíz Cuadrada vs Puntuación", 
       x = "sqrt(Asistencia)", y = "Puntuación de Examen") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Gráfico Box-Cox
grafico_corr_boxcox <- ggplot(student_data, aes(x = Asistencia_boxcox, y = Puntuacion_Examen)) +
  geom_point(color = "#5BC0EB", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Asistencia Box-Cox vs Puntuación", 
       x = "Box-Cox(Asistencia)", y = "Puntuación de Examen") +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 10),
    axis.line = element_line(color = "black"),
    axis.ticks = element_line(color = "black"),
    panel.grid = element_blank(),
    panel.background = element_blank()
  )

# Mostrar en una fila
grid.arrange(grafico_corr_sqrt, grafico_corr_boxcox, ncol = 2)
```

El gráfico de dispersión combinado revela que las transformaciones no modifican significativamente la relación entre Asistencia y Puntuación de Examen. La tendencia positiva observada en la variable original se mantiene en todas las versiones transformadas.

Dado que la Asistencia Original ya presenta una relación positiva moderada con la Puntuación de Examen, podría utilizarse directamente en el modelo. No obstante, si al analizar los residuos del modelo de regresión se detectan problemas de normalidad o linealidad, la transformación raíz cuadrada sería la primera opción a considerar, aunque se evaluarán también las otras transformaciones para seleccionar la más adecuada.

## Codificación de Variables Categóricas

La codificación de variables categóricas es un paso esencial en modelos predictivos, como la regresión lineal, que requieren que todas las variables sean numéricas. En este caso, se utiliza One-Hot Encoding, una técnica que convierte cada categoría de una variable en una nueva columna binaria. Estas columnas toman el valor 1 si el registro pertenece a esa categoría y 0 en caso contrario.

Las variables seleccionadas para la codificación se han organizado según los factores internos, externos y dependientes de la escuela:

-   **Factores Internos:**
    -   Nivel de Motivación
-   **Factores Externos:**
    -   Involucramiento Parental.
-   **Factores Dependientes:**
    -   Tipo de Escuela
    -   Calidad del Profesor

### Aplicación de One-Hot Encoding

Para realizar la codificación, se eliminó una columna de referencia en cada variable para evitar problemas de multicolinealidad. La multicolinealidad ocurre cuando las variables predictoras están altamente correlacionadas entre sí, lo que puede distorsionar los coeficientes en un modelo de regresión lineal y dificultar la interpretación de los efectos de cada variable.

Por ejemplo, si la variable `Calidad_Profesor` tiene las categorías **Alta**, **Media** y **Baja**, solo se incluiran dos nuevas columnas (`Calidad_Profesor_Alta`y `Calidad_Profesor_Media`), mientras que la categoría **Baja** se tomará como referencia implícita.

```{r}
# Crear una nueva base de datos con variables codificadas
student_data_encoded <- dummy_cols(student_data, 
                                   select_columns = c("Nivel_Motivacion", "Involucramiento_Parental", 
                                                      "Calidad_Profesor", "Tipo_Escuela"),
                                   remove_first_dummy = TRUE,   # Elimina una columna de referencia
                                   remove_selected_columns = TRUE) # Elimina las columnas originales
```

## Verificación de las Nuevas Variables

Se realizó una verificación de las columnas generadas para confirmar que la codificación se realizó correctamente. Esto incluye:

-   Los nombres de las nuevas columnas generadas por One-Hot Encoding.\
-   Los valores binarios (0 o 1) que se asignaron correctamente a las categorías correspondientes.

```{r}
head(student_data_encoded)
```

Los nombres de las columnas confirmaron que las nuevas variables fueron creadas con prefijos que indican su variable original. Por ejemplo, `Calidad_Profesor` generó la columna `Calidad_Profesor_Alta` y `Calidad_Profesor_Media`. Esta estructura permite que las variables categóricas se integren de manera efectiva en el modelo de regresión.

```{r}
colnames(student_data_encoded)
```
